apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: sort-dataset-generator
spec:
  type: Scala
  mode: cluster
  image: mesosphere/spark:spark-3.0.0-hadoop-2.9-k8s
  imagePullPolicy: Always
  mainClass: sorting.DatasetGenerator
  mainApplicationFile: "https://kudo-spark.s3-us-west-2.amazonaws.com/spark-scala-tests-3.0.0-20200819.jar"
  arguments:
    - "--num-files"
    - "1000"
    - "--num-records"
    - "1000000"
    - "--static-prefix-length"
    - "128"
    - "--random-suffix-length"
    - "128"
    - "--value-size-bytes"
    - "1000000"
    - "--output-path"
    - "TARGET_S3_PATH"
  sparkConf:
    "spark.scheduler.maxRegisteredResourcesWaitingTime": "2400s"
    "spark.scheduler.minRegisteredResourcesRatio": "1.0"
    "spark.hadoop.fs.s3a.impl": "org.apache.hadoop.fs.s3a.S3AFileSystem"
    "spark.hadoop.fs.s3a.aws.credentials.provider": "org.apache.hadoop.fs.s3a.TemporaryAWSCredentialsProvider"
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version": "2"
    "spark.hadoop.fs.s3a.endpoint": "S3_ENDPOINT"
    "spark.hadoop.fs.s3a.access.key": "AWS_ACCESS_KEY_ID"
    "spark.hadoop.fs.s3a.secret.key": "AWS_SECRET_ACCESS_KEY"
    "spark.hadoop.fs.s3a.session.token": "AWS_SESSION_TOKEN"
  sparkVersion: "3.0.0"
  restartPolicy:
    type: Never
  driver:
    cores: 1
    memory: "1g"
    labels:
      version: 3.0.0
    serviceAccount: SERVICE_ACCOUNT_NAME
  executor:
    cores: 1
    instances: NUM_EXECUTORS
    memory: "3g"
    labels:
      version: 3.0.0
