# Spark History Server

### Prerequisites

Required software:
* K8s cluster
* [KUDO CLI Plugin](https://kudo.dev/docs/#install-kudo-cli) 0.7.3 or higher
* [kubens](https://github.com/ahmetb/kubectx)

### Installing Spark Operator with History Server Enabled

```
kubens spark-operator
kubectl kudo install ./kudo-operator -p operatorImageName=mesosphere/kudo-spark-operator -p operatorVersion=latest -p enableHistoryServer=true
```

This will setup Spark History Server Pod and Service with Spark Event Log directory pointing to a location `/opt/spark/work-dir` (which you can change by passing another location to a parameter `historyServerFsLogDirectory`). This location is local to a Pod of Spark History Server. If we wnat to make it persistent and shared between different Pods, we have to create a PVC (Persistent Volume Claim) and pass it while starting the Spark History Server.

Suppose you have created a PVC with name `history-server-pvc`, than you can install Spark Operator using following command by passing PVC name.

```
kubectl kudo install ./kudo-operator -p operatorImageName=mesosphere/kudo-spark-operator -p operatorVersion=latest -p enableHistoryServer=true -p historyServerPVCName=history-server-pvc
```

### Creating Spark Application

Make sure `specs/spark-application.yaml` has these two configurations added under `spec.sparkConf`.

```
"spark.eventLog.enabled": "true"
"spark.eventLog.dir": "/opt/spark/work-dir"
```

If PVC is passed while installing the Spark Operator, make sure these two fields are also added with following values:

```
# Add this under SparkApplicationSpec
Volumes:
- name: pvc-storage
  persistentVolumeClaim:
    claimName: history-server-pvc

# Add this under SparkPodSpec
volumeMounts:
- mountPath: "/opt/spark/work-dir"
  name: pvc-storage
```

Now we can run the application as follows:

```
kubectl apply -f specs/spark-application.yaml
```

If we don't create a PVC and run the Spark Operator with History Server enabled as well as launch the Spark Application, we won't be able to see the logs generated by the application. Because the Pod running the application has its own local log directory and the Pod running the history server has its own local log directory. By creating PVC, we are making it persistent and shared among these two Pods.

### Accessing Spark History Server UI

By running following command we can get the name of the Pod running the Spark History Server.

```
kubectl get pods
```

Now you can run this command to expose the UI in your local machine.
`kubectl port-forward <history-server-pod-name> <local-port>:<container-port>`

For example:
```
kubectl port-forward spark-history-server-7f876d79b5-c9pdl 18080:18080
```
