apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: {{ .Name }}
  namespace: {{ .Namespace }}
spec:
  type: Scala
  mode: cluster
  image: {{ .Image }}
  imagePullPolicy: Always
  mainClass: org.apache.spark.examples.ml.LinearRegressionExample
  mainApplicationFile: "local:///opt/spark/examples/jars/spark-examples_2.11-{{ .SparkVersion }}.jar"
  arguments:
    - "--regParam"
    - "0.15"
    - "--elasticNetParam"
    - "1.0"
    - "--maxIter"
    - "1000000"
    - "/opt/spark/data/mllib/sample_linear_regression_data.txt"
  sparkConf:
    "spark.scheduler.maxRegisteredResourcesWaitingTime": "2400s"
    "spark.scheduler.minRegisteredResourcesRatio": "1.0"
    "spark.eventLog.enabled": "true"
    "spark.eventLog.dir": "{{ .Params.AwsBucketPath }}"
    {{- if .Params.AwsSessionToken }}
    "spark.hadoop.fs.s3a.access.key": "{{ .Params.AwsAccessKey }}"
    "spark.hadoop.fs.s3a.secret.key": "{{ .Params.AwsAccessSecret }}"
    "spark.hadoop.fs.s3a.session.token": "{{ .Params.AwsSessionToken }}"
    "spark.hadoop.fs.s3a.aws.credentials.provider": "org.apache.hadoop.fs.s3a.TemporaryAWSCredentialsProvider"
    {{- else }}
    "spark.hadoop.fs.s3a.access.key": "{{ .Params.AwsAccessKey }}"
    "spark.hadoop.fs.s3a.secret.key": "{{ .Params.AwsAccessSecret }}"
    {{- end }}
  deps:
    jars:
      - local:///opt/spark/examples/jars/scopt_2.11-3.7.0.jar
  sparkVersion: {{ .SparkVersion }}
  restartPolicy:
    type: Never
  driver:
    cores: 1
    memory: "512m"
    labels:
      version: {{ .SparkVersion }}
    serviceAccount: {{ .ServiceAccount }}
  executor:
    cores: 1
    instances: 1
    memory: "512m"
    labels:
      version: {{ .SparkVersion }}
