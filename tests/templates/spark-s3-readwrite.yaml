apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: {{ .Name }}
  namespace: {{ .Namespace }}
spec:
  type: Scala
  mode: cluster
  image: {{ .Image }}
  imagePullPolicy: Always
  mainClass: S3Job
  mainApplicationFile: "https://kudo-spark.s3-us-west-2.amazonaws.com/spark-scala-tests-2.4.5-20200225.jar"
  sparkConf:
    "spark.scheduler.maxRegisteredResourcesWaitingTime": "2400s"
    "spark.scheduler.minRegisteredResourcesRatio": "1.0"
    "spark.hadoop.fs.s3a.impl": "org.apache.hadoop.fs.s3a.S3AFileSystem"
    {{- if .Params.AwsSessionToken }}
    "spark.hadoop.fs.s3a.aws.credentials.provider": "org.apache.hadoop.fs.s3a.TemporaryAWSCredentialsProvider"
    {{- end }}
  sparkVersion: {{ .SparkVersion }}
  arguments:
    - "--readUrl"
    - {{ .Params.ReadUrl }}
    - "--writeUrl"
    - {{ .Params.WriteUrl }}
  restartPolicy:
    type: Never
  driver:
    cores: 1
    memory: "512m"
    labels:
      version: {{ .SparkVersion }}
    serviceAccount: {{ .ServiceAccount }}
    env:
      - name: AWS_ACCESS_KEY_ID
        valueFrom:
          secretKeyRef:
            name: {{ .Params.AwsSecretName }}
            key: AWS_ACCESS_KEY_ID
      - name: AWS_SECRET_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: {{ .Params.AwsSecretName }}
            key: AWS_SECRET_ACCESS_KEY
      - name: AWS_SESSION_TOKEN
        valueFrom:
          secretKeyRef:
            name: {{ .Params.AwsSecretName }}
            key: AWS_SESSION_TOKEN
            optional: true
  executor:
    cores: 1
    instances: 1
    memory: "512m"
    labels:
      version: {{ .SparkVersion }}
