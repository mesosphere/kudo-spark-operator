apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: spark-hdfs-test
spec:
  type: Scala
  mode: cluster
  image: mesosphere/spark-dev:e0f9eb2dcc71b2de6d3e0ce8a0f26c059430b946
  imagePullPolicy: Always
  mainClass: org.apache.spark.examples.HdfsTest
  mainApplicationFile: "local:///opt/spark/examples/jars/spark-examples_2.12-3.0.0.jar"
  arguments:
  - "hdfs://namenode.hdfs-kerberos.svc.cluster.local:9000/spark/README.txt"
  sparkConf:
    "spark.scheduler.maxRegisteredResourcesWaitingTime": "2400s"
    "spark.scheduler.minRegisteredResourcesRatio": "1.0"
    "spark.kubernetes.submission.connectionTimeout": "60000"
    "spark.kubernetes.submission.requestTimeout": "60000"
  hadoopConfigMap: hadoop-conf
  sparkVersion: 3.0.0
  restartPolicy:
    type: Never
  driver:
    cores: 1
    memory: "512m"
    labels:
      version: 3.0.0
    serviceAccount: spark-spark-service-account
    secrets:
    - name: hadoop-token
      path: /mnt/secrets
      secretType: HadoopDelegationToken
  executor:
    cores: 1
    instances: 1
    memory: "512m"
    deleteOnTermination: false
    labels:
      version: 3.0.0
    secrets:
    - name: hadoop-token
      path: /mnt/secrets
      secretType: HadoopDelegationToken
